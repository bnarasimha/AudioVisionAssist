## AudioVisionAssist

1. Captures live camera feed, detects objects.
2. Passing the detected objects to LLM to get an informatory message to user.
3. As of now printing the LLM response on the terminal
4. Planning to say it out loud via tts feature to help people to understand surroundings
